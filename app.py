import streamlit as st
import pandas as pd
import numpy as np
import altair as alt
import joblib
import re
from io import BytesIO


st.set_page_config(page_title="üìß Email Spam/Phishing Report", page_icon="üìß", layout="wide")
st.title("üìß Email Spam/Phishing Classification Dashboard")
st.caption("D·ª±a tr√™n m√¥ h√¨nh TF-IDF + RandomForest ƒë√£ train t·ª´ `spam.csv`.")


@st.cache_resource(ttl=3600)
def load_artifacts():
    model = joblib.load("spam_classifier_model.pkl")
    vectorizer = joblib.load("spam_tfidf_vectorizer.pkl")
    return model, vectorizer


def preprocess_text(text: str) -> str:
    text = str(text).lower()
    text = re.sub(r"[^a-zA-Z\s]", "", text)
    text = " ".join(text.split())
    return text


@st.cache_data(ttl=600)
def load_base_data(max_rows_preview: int = 5000):
    """Load nhanh: ch·ªâ ƒë·ªçc preview v√† t√≠nh ph√¢n ph·ªëi nh√£n theo chunks ƒë·ªÉ tr√°nh t·∫£i to√†n b·ªô file."""
    usecols = ["Email Text", "Email Type"]
    try:
        # Preview nhanh cho hi·ªÉn th·ªã b·∫£ng
        df_preview = pd.read_csv("spam.csv", usecols=usecols, nrows=max_rows_preview)
        df_preview = df_preview.dropna(subset=usecols).copy()

        # ƒê·∫øm ph√¢n ph·ªëi nh√£n theo t·ª´ng kh·ªëi (memory-efficient)
        label_counts = {}
        for chunk in pd.read_csv("spam.csv", usecols=usecols, chunksize=50000):
            vc = chunk["Email Type"].value_counts(dropna=True)
            for k, v in vc.items():
                label_counts[k] = label_counts.get(k, 0) + int(v)

        dist = (
            pd.DataFrame({"Lo·∫°i": list(label_counts.keys()), "S·ªë l∆∞·ª£ng": list(label_counts.values())})
            .sort_values("S·ªë l∆∞·ª£ng", ascending=False)
            .reset_index(drop=True)
        )
        return df_preview, dist
    except Exception:
        return pd.DataFrame(columns=usecols), pd.DataFrame(columns=["Lo·∫°i", "S·ªë l∆∞·ª£ng"])  # Fallback


def predict_text(model, vectorizer, email_text: str) -> dict:
    processed = preprocess_text(email_text)
    text_length = len(processed)
    word_count = len(processed.split())
    X_text = vectorizer.transform([processed])
    X_other = np.array([[text_length, word_count]])
    X = np.hstack([X_text.toarray(), X_other])
    pred = model.predict(X)[0]
    proba = model.predict_proba(X)[0]
    label = "Phishing Email" if pred == 1 else "Safe Email"
    return {
        "prediction": label,
        "phishing_probability": float(proba[1]),
        "safe_probability": float(proba[0]),
    }


def predict_dataframe(model, vectorizer, df: pd.DataFrame, text_col: str) -> pd.DataFrame:
    df_proc = df.copy()
    df_proc[text_col] = df_proc[text_col].astype(str)
    df_proc["processed_text"] = df_proc[text_col].apply(preprocess_text)
    df_proc["text_length"] = df_proc["processed_text"].apply(len)
    df_proc["word_count"] = df_proc["processed_text"].apply(lambda x: len(x.split()))
    X_text = vectorizer.transform(df_proc["processed_text"])
    X_other = df_proc[["text_length", "word_count"]].values
    X = np.hstack([X_text.toarray(), X_other])
    preds = model.predict(X)
    probas = model.predict_proba(X)
    reverse_mapping = {0: "Safe Email", 1: "Phishing Email"}
    df_out = df_proc.copy()
    df_out["predicted_type"] = [reverse_mapping[p] for p in preds]
    df_out["phishing_probability"] = probas[:, 1]
    df_out["safe_probability"] = probas[:, 0]
    return df_out


tab_overview, tab_single, tab_batch, tab_reports = st.tabs([
    "üìå T·ªïng quan", "üìù D·ª± ƒëo√°n 1 email", "üìÅ D·ª± ƒëo√°n theo CSV", "üìà B√°o c√°o/ƒê·ªì th·ªã",
])


with tab_overview:
    st.subheader("T·ªïng quan d·ªØ li·ªáu")
    base_df, dist = load_base_data()
    if not base_df.empty:
        st.write("M·ªôt ph·∫ßn d·ªØ li·ªáu g·ªëc (spam.csv):")
        st.dataframe(base_df.head(20), use_container_width=True)
        # dist ƒë√£ t√≠nh s·∫µn theo chunks ƒë·ªÉ nhanh h∆°n
        chart = alt.Chart(dist).mark_bar().encode(
            x=alt.X("Lo·∫°i:N", sort="-y"), y="S·ªë l∆∞·ª£ng:Q", color="Lo·∫°i:N", tooltip=["Lo·∫°i", "S·ªë l∆∞·ª£ng"]
        ).properties(height=300)
        st.altair_chart(chart, use_container_width=True)
    else:
        st.info("Kh√¥ng t√¨m th·∫•y ho·∫∑c kh√¥ng ƒë·ªçc ƒë∆∞·ª£c spam.csv. Vui l√≤ng ƒë·∫£m b·∫£o file t·ªìn t·∫°i.")


with tab_single:
    st.subheader("D·ª± ƒëo√°n n·ªôi dung email ƒë∆°n l·∫ª")
    model, vectorizer = load_artifacts()
    email_text = st.text_area("Nh·∫≠p n·ªôi dung email", height=180)
    col_a, col_b = st.columns([1, 2])
    with col_a:
        if st.button("Ph√¢n lo·∫°i"):
            if email_text.strip():
                res = predict_text(model, vectorizer, email_text)
                st.success(f"K·∫øt qu·∫£: {res['prediction']}")
                st.metric("X√°c su·∫•t Phishing", f"{res['phishing_probability']:.3f}")
                st.metric("X√°c su·∫•t Safe", f"{res['safe_probability']:.3f}")
            else:
                st.warning("Vui l√≤ng nh·∫≠p n·ªôi dung email.")
    with col_b:
        st.caption("N·ªôi dung ƒë√£ chu·∫©n ho√° (xem c√°ch ti·ªÅn x·ª≠ l√Ω):")
        if email_text.strip():
            st.code(preprocess_text(email_text))


with tab_batch:
    st.subheader("D·ª± ƒëo√°n theo CSV")
    st.caption("CSV c·∫ßn c√≥ c·ªôt 'Email Text'. B·∫°n c√≥ th·ªÉ ƒë·ªïi t√™n c·ªôt b√™n d∆∞·ªõi.")
    model, vectorizer = load_artifacts()
    uploaded = st.file_uploader("T·∫£i l√™n CSV", type=["csv"])
    text_col = st.text_input("T√™n c·ªôt vƒÉn b·∫£n", value="Email Text")
    if uploaded is not None:
        try:
            in_df = pd.read_csv(uploaded)
            if text_col not in in_df.columns:
                st.error(f"Kh√¥ng t√¨m th·∫•y c·ªôt '{text_col}' trong file.")
            else:
                out_df = predict_dataframe(model, vectorizer, in_df, text_col=text_col)
                st.success("ƒê√£ ph√¢n lo·∫°i xong.")
                st.dataframe(out_df.head(50), use_container_width=True)

                # Bi·ªÉu ƒë·ªì ph√¢n ph·ªëi k·∫øt qu·∫£
                dist = out_df["predicted_type"].value_counts().reset_index()
                dist.columns = ["Lo·∫°i", "S·ªë l∆∞·ª£ng"]
                chart = alt.Chart(dist).mark_bar().encode(
                    x=alt.X("Lo·∫°i:N", sort="-y"), y="S·ªë l∆∞·ª£ng:Q", color="Lo·∫°i:N", tooltip=["Lo·∫°i", "S·ªë l∆∞·ª£ng"]
                ).properties(height=300)
                st.altair_chart(chart, use_container_width=True)

                # Download k·∫øt qu·∫£
                csv_bytes = out_df.to_csv(index=False).encode("utf-8")
                st.download_button("T·∫£i k·∫øt qu·∫£ CSV", csv_bytes, file_name="predictions.csv", mime="text/csv")
        except Exception as e:
            st.exception(e)


with tab_reports:
    st.subheader("B√°o c√°o/ƒê·ªì th·ªã")
    st.caption("H√¨nh t·ªïng h·ª£p: Learning curve, Validation curve, ROC, Confusion matrix")
    try:
        st.image("report_plots.png", caption="Model Diagnostics", use_column_width=True)
    except Exception:
        st.info("Kh√¥ng t√¨m th·∫•y 'report_plots.png'. H√£y ch·∫°y: python plot_report.py")

